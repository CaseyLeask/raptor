### Conceptual model

An application is composed of resources. A resource includes database records, presenters, views, and routes, or any subset of those. Not all resources can be accessed directly through HTTP, and not all resources map directly onto database records.

Resources are composed of plain old Ruby objects. Sometimes, Raptor uses convention-based methods to instantiate or interact with them, but the objects themselves are simple. There are no base classes to inherit from.

The one exception to this is routing, because it's pure configuration.

### Application

An application is just a Ruby script:

    #!/usr/bin/env ruby

    require 'resources/posts'
    require 'resources/users'

    Raptor.new([Posts, Users]).attack!

Running this script will start a server, just like Sinatra would. There's no autoloader and no discovery of your code: you explicitly require your resources and give them to Raptor.

### Raptor request process

- Step through routes, choosing the first that matches
- Delegate to the domain object, inferring arguments as needed
  - If an exception is raised, route it and end this process
- Instantiate the presenter with the domain object
- Pass the presenter to the template

### Implementation

It's as you'd expect:

    class App
      def call(env)
        route = routes.find { |r| r.matches?(env) }
        route.call(env)
      end
    end

    class Route
      def call(env)
        begin
          domain_object = route.build_domain_object
        rescue Exception => e
          presenter = route.handle_exception(exception)
        end
        presenter = route.build_presenter(domain_object)
        render(presenter)
      end
    end

### Argument inference

Domain objects, presenters, and requirements can infer certain arguments. For example, consider this presenter:

    class PresentsUsers
      def initialize(params, user)
        @params = params
        @user = user
      end

      ...
    end

Because the Presenter's initializer takes an argument named `params`, the router will automatically be populated with the params hash when the router instantiates it.

From the application's point of view, this achieves roughly the same result as a Rails controller: you can access the params, or plenty of other request-related state, if you need to. But has some additional benefits:

* More than just request-state can be inferred. If your presenter method takes an argument named `post`, and there's a resource named Post, and there's a param value at `params[:post][:id]`, then Raptor will automatically retrieve that post for you. By simply naming your argument `post`, you're telling the Raptor router that you want the relevant post record injected.

* Testability: the presenter (or domain object or requirement) is still just a regular object with a regular initializer. When you test it, you can just new it up with appropriate arguments. There are no controller classes full of implicit interactions.

### Design Notes / Constraints

- All scripts will comform to Unix argument conventions
- All scripts will die immediately on ^C
- All scripts, and framework loads, will take less than 100 ms
- Autoreload will happen by killing and restarting, not in-place
- Releases will follow semantic versioning

### Sanity Notes

- Mutating a record in a presenter is an error
- A resource may not be named "params"

### Testing

- Running request tests generates transcripts of the requests as text files. Reviewing these on commit can reveal unintended changes.
- Add request metatests that duplicate requests that should be idempotent (everything except POSTs) and verify that they actually are. (Good idea?)

### Possible database layer primitives

https://github.com/nateware/redis-objects

